{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c177f93-f39c-4139-b0dd-04703c23806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "726ac468-aeca-468c-836e-c391dc196fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\basellmchatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a968f61-e48c-4ce0-9309-05575ab51190",
   "metadata": {},
   "source": [
    "# Call api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0708e6f-2271-4b44-9b33-af6553a3401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access token\n",
    "HF_TOKEN = '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'\n",
    "# create llm model\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\",  # Replace with the model of your choice\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 256},\n",
    "    huggingfacehub_api_token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4072463a-7647-4022-8469-1a56ea4d46c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is the process of learning to recognize patterns in data.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test the model with a prompt\n",
    "response = llm.invoke(\"Explain the concept of machine learning in simple terms.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a67d01a-140a-4589-be9a-28cdc9240c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access token\n",
    "HF_TOKEN = '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'\n",
    "# create llm model\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"microsoft/phi-2\",  # Replace with the model of your choice\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 256},\n",
    "    huggingfacehub_api_token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb2952dc-ab49-4960-9a44-d4352845c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the concept of machine learning in simple terms.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "Machine learning is a way of teaching computers to learn from data and make predictions or decisions without being explicitly programmed. For example, a machine learning algorithm can learn from a large amount of pictures of cats and dogs and then be able to identify whether a new picture is of a cat or a dog. Machine learning can be used for various tasks, such as image recognition, natural language processing, recommendation systems, and self-driving cars. Machine learning is based on the idea that computers can learn from patterns and examples in data, and improve their performance over time.\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 795 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test the model with a prompt\n",
    "response = llm.invoke(\"Explain the concept of machine learning in simple terms.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c23be56-33e1-4dd5-bfcd-9c514e8e4a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\basellmchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--google--flan-t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 203 ms\n",
      "Wall time: 6.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the tokenizer corresponding to the specified model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61638692-32bb-4b6e-8e9c-2b920bd655a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 156 ms\n",
      "Wall time: 558 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the tokenizer corresponding to the specified model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655db1c2-4ee9-480d-8779-09455e49cd3c",
   "metadata": {},
   "source": [
    "# Self-hosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d7a29b-a51d-4039-a950-0bfad9defe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\basellmchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--microsoft--phi-2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards: 100%|██████████| 2/2 [03:34<00:00, 107.04s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:47<00:00, 23.91s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "model_name: str = 'microsoft/phi-2'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76808f37-7a92-44d7-9167-8b16d8c22e40",
   "metadata": {},
   "source": [
    "# Connect function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15574893-0003-4a12-a721-7736aa6382da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Additional Parameters and Considerations:\\nWhile these are the primary parameters used in the given code, there are other potential parameters you might consider depending on the specific model and task:\\n\\ntop_p: Controls the diversity of the generated text by selecting the top-p most probable tokens.\\nnum_beams: Specifies the number of beams to use for beam search decoding, which can improve the quality of the generated text.\\nearly_stopping: Determines whether to stop the generation process early if the generated text reaches a certain quality threshold.\\nno_repeat_ngram_size: Prevents the model from repeating the same ngram (sequence of tokens) multiple times.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Additional Parameters and Considerations:\n",
    "While these are the primary parameters used in the given code, there are other potential parameters you might consider depending on the specific model and task:\n",
    "\n",
    "top_p: Controls the diversity of the generated text by selecting the top-p most probable tokens.\n",
    "num_beams: Specifies the number of beams to use for beam search decoding, which can improve the quality of the generated text.\n",
    "early_stopping: Determines whether to stop the generation process early if the generated text reaches a certain quality threshold.\n",
    "no_repeat_ngram_size: Prevents the model from repeating the same ngram (sequence of tokens) multiple times.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ed6243-add6-4004-9cc7-5baa2d1e0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hf_llm(model_name: str = \"microsoft/phi-2\", call_model_api=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Creates and returns a HuggingFace LLM pipeline for text generation.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the pre-trained model to load from the HuggingFace model hub.\n",
    "                         Defaults to \"microsoft/phi-2\".\n",
    "        max_new_tokens (int): The maximum number of tokens to generate in the output sequence.\n",
    "                              Defaults to 1024.\n",
    "        **kwargs: Additional keyword arguments that can be passed to customize the model or tokenizer.\n",
    "\n",
    "    Returns:\n",
    "        llm: A HuggingFacePipeline instance configured for text generation.\n",
    "    \"\"\"\n",
    "    # Define additional generation parameters, such as sampling temperature.\n",
    "    gen_kwargs = {\n",
    "        'temperature': kwargs.get('temperature', 0.5),\n",
    "        'max_new_tokens': kwargs.get('max_new_tokens', 1024)\n",
    "    }\n",
    "\n",
    "    if call_model_api:\n",
    "        # Access token\n",
    "        HF_TOKEN = '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'\n",
    "              \n",
    "        # create llm model\n",
    "        llm = HuggingFaceHub(\n",
    "            repo_id=model_name,\n",
    "            model_kwargs=gen_kwargs,\n",
    "            huggingfacehub_api_token=HF_TOKEN\n",
    "        )\n",
    "    else:\n",
    "        # Load a pre-trained causal language model with low memory usage optimization for CPUs.\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        # Load the tokenizer corresponding to the specified model.\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # Create a text-generation pipeline using the model and tokenizer.\n",
    "        model_pipeline = pipeline(\n",
    "            'text-generation',\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=kwargs.get('max_new_tokens', 1024),\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            device_map='auto'\n",
    "        )\n",
    "        # Wrap the pipeline in a HuggingFacePipeline object for further use.\n",
    "        llm = HuggingFacePipeline(\n",
    "            pipeline=model_pipeline,\n",
    "            model_kwargs=gen_kwargs\n",
    "        )\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0cb4a0-d7cf-412f-bf0f-e2ae69ea1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Using default parameters\n",
    "llm = get_hf_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0092e4da-c5cc-4c6d-a7f6-a75d28d2573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the concept of machine learning in simple terms.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "Machine learning is a branch of artificial intelligence that allows computers to learn from data and make predictions or decisions without being explicitly programmed. For example, a machine learning algorithm can learn to recognize faces from a large dataset of images and then identify new faces in new images. Machine learning can be used for various tasks, such as image analysis, speech recognition, natural language processing, and recommendation systems.\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test the model with a prompt\n",
    "response = llm.invoke(\"Explain the concept of machine learning in simple terms.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ac79c57-5f5c-4d5a-b8d5-247f7f636dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Customizing model and temperature\n",
    "llm = get_hf_llm(temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f1b7530-3973-4f2f-b73a-496b240440d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the concept of machine learning in simple terms. No input. OUTPUT: Machine learning is a type of artificial intelligence that allows computers to learn from data and experience, without being explicitly programmed. Machine learning algorithms can analyze large amounts of data, find patterns and trends, and make predictions or decisions based on the data. Machine learning can be used for various applications, such as image recognition, natural language processing, recommendation systems, and self-driving cars.\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test the model with a prompt\n",
    "response = llm.invoke(\"Explain the concept of machine learning in simple terms.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1c8e7f2-548a-4f69-9530-53df8e29f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Customizing max_new_tokens and temperature\n",
    "llm = get_hf_llm(max_new_tokens=512, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf3fe9d7-b3ce-4137-b3f4-3eec1aed39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the concept of machine learning in simple terms.\n",
      "## INPUT\n",
      "Machine learning is a branch of artificial intelligence that enables computers to learn from data and experience without being explicitly programmed.\n",
      "##OUTPUT\n",
      "Machine learning is a way of making computers smarter by letting them learn from what they see and do.\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test the model with a prompt\n",
    "response = llm.invoke(\"Explain the concept of machine learning in simple terms.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b259483-cc56-4a72-be67-cf2899fc9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Customizing all parameters\n",
    "llm = get_hf_llm(max_new_tokens=256, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "057d7225-4ed7-4f8a-8171-b9a003d7f321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the concept of machine learning in simple terms.\n",
      "## INPUT\n",
      "Machine learning is a branch of artificial intelligence that enables computers to learn from data and experience without being explicitly programmed.\n",
      "##OUTPUT\n",
      "Machine learning is a way of making computers smarter by letting them learn from what they see and do.\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test the model with a prompt\n",
    "response = llm.invoke(\"Explain the concept of machine learning in simple terms.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd040f3",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8662f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def remove_non_utf8_characters(text):\n",
    "    return ''.join(char for char in text if ord(char) < 128)\n",
    "def load_pdf(pdf_file):\n",
    "    docs = PyPDFLoader(pdf_file, extract_images=True).load()\n",
    "    text = ''\n",
    "    for doc in docs:\n",
    "        text += remove_non_utf8_characters(doc.page_content)\n",
    "\n",
    "    return text\n",
    "\n",
    "CVs_content1 = load_pdf('..\\data\\CVs\\Smith Resume.pdf')\n",
    "CVs_content2 = load_pdf('..\\data\\CVs\\Alice Clark CV.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090ab37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Michael Smith',\n",
       " 'location': 'Manchester, UK',\n",
       " 'contact_information': {'email': 'indeed.com/r/falicent/140749dace5dc26f'},\n",
       " 'experience': '10+ years of Experience in Designing, Development, Administration, Analysis, Management in the Business Intelligence Data warehousing, Client Server Technologies, Web-based Applications, cloud solutions and Databases.',\n",
       " 'skills': ['BI',\n",
       "  'Big Data',\n",
       "  'Azure',\n",
       "  'Data warehouse',\n",
       "  'Database',\n",
       "  'Cloud platform',\n",
       "  'Big Data',\n",
       "  'Azure data lake store/analytics',\n",
       "  'Azure data factory',\n",
       "  'U-SQL',\n",
       "  'Problem solving',\n",
       "  'Project lifecycle',\n",
       "  'Project manager',\n",
       "  'Technical assistance'],\n",
       " 'work_experience': [{'company': 'Microsoft',\n",
       "   'location': 'Manchester, UK',\n",
       "   'duration': 'December 2015 to Present',\n",
       "   'position': 'Software Engineer',\n",
       "   'projects': [{'name': 'Microsoft Rewards Live dashboards',\n",
       "     'description': 'Microsoft rewards is loyalty program that rewards Users for browsing and shopping online.',\n",
       "     'technologies': ['Event hub', 'Stream analytics', 'Power BI'],\n",
       "     'responsibilities': ['Created stream analytics jobs to process event hub data',\n",
       "      'Created Power BI live dashboard to show live usage traffic, weekly trends, cards, charts to show top/bottom 10 offers and usage metrics.']},\n",
       "    {'name': 'Microsoft Rewards Data Insights',\n",
       "     'description': 'Microsoft rewards is loyalty program that rewards Users for browsing and shopping online.',\n",
       "     'technologies': ['Cosmos (Microsoft big-data platform)',\n",
       "      'c#',\n",
       "      'X-flow job monitoring',\n",
       "      'Power BI'],\n",
       "     'responsibilities': ['Created big data scripts in cosmos',\n",
       "      'C# data extractors, processors and reducers for data transformation',\n",
       "      'Power BI dashboards']},\n",
       "    {'name': 'End to end tracking Tool',\n",
       "     'description': 'This is real-time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing inside ICOE.',\n",
       "     'technologies': ['Azure Document db',\n",
       "      'Azure web job',\n",
       "      'Web APP',\n",
       "      'RBAC',\n",
       "      'Angular JS'],\n",
       "     'responsibilities': ['Document dB stored procedures.',\n",
       "      'Web job to process event hub data and populate Document db Web App API.',\n",
       "      'Stream analytics job to transform data',\n",
       "      'Power BI reports']},\n",
       "    {'name': 'Biztrack Tracking Tool',\n",
       "     'description': 'This is real-time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing inside ICOE.',\n",
       "     'technologies': ['SQL server 2014', 'SSIS', '.net API', 'Angular JS'],\n",
       "     'responsibilities': ['ETL solution to transform business transactions data stored in Biztalk tables.',\n",
       "      'SQL azure tables, stored procedures, User defined functions.',\n",
       "      'Performance tuning.',\n",
       "      'Web API enhancements.']}]}],\n",
       " 'education': [{'university': 'The University of Manchester', 'year': '2007'}],\n",
       " 'additional_skills': ['Problem solving',\n",
       "  'Project lifecycle',\n",
       "  'Project manager',\n",
       "  'Technical assistance'],\n",
       " 'additional_information': ['Excellent analytical, problem solving, communication, knowledge transfer and interpersonal skills with ability to interact with individuals at all the levels',\n",
       "  'Quick learner and maintains cordial relationship with project manager and team members and good performer both in team and independent job environments',\n",
       "  'Positive attitude towards superiors & peers',\n",
       "  'Supervised junior developers throughout project lifecycle and provided technical assistance.']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from typing import List, Optional\n",
    "import uuid\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"cv_content\"],  # Only include the actual variables used in the template\n",
    "    template=\"\"\"\n",
    "    You are a highly skilled language model specializing in extracting structured information from unstructured text. Your task is to parse resumes or CVs into a structured JSON format. Extract and organize the following information:\n",
    "\n",
    "    - **Name**: The full name of the candidate.\n",
    "    - **Location**: The city and country where the candidate resides.\n",
    "    - **Contact_Information**: Email address, phone number and other contact details (if available).\n",
    "    - **Experience**: Total years of professional experience or a summary.\n",
    "    - **Skills**: List of technical, professional, or interpersonal skills mentioned.\n",
    "    - **Work_Experience**: For each job, include:\n",
    "      - Company: Name of the organization.\n",
    "      - Location: City and country.\n",
    "      - Duration: Start and end dates or the total duration.\n",
    "      - Position: Job title.\n",
    "      - Projects: For each project, include:\n",
    "        - Name: Project name.\n",
    "        - Description: What the project was about.\n",
    "        - Technologies: Technologies used in the project.\n",
    "        - Responsibilities: Key responsibilities undertaken.\n",
    "    - **Education**: Include:\n",
    "      - University: Name of the institution.\n",
    "      - Year: Graduation year or years of attendance.\n",
    "    - **Additional_Skills**: Any extra skills or certifications.\n",
    "    - **Additional_Information**: Other professional qualities or awards, or achievements.\n",
    "\n",
    "    Return the output strictly in JSON format, without any additional commentary or text.\n",
    "    \n",
    "    Example:\n",
    "    CV Content:\n",
    "    ```\n",
    "    John Doe\n",
    "    Address: New York, USA\n",
    "    Email: john.doe@example.com | Phone: +123456789\n",
    "    Professional Experience: Over 10 years in software development and project management.\n",
    "    Skills: Python, JavaScript, React, Project Management, Agile Methodologies.\n",
    "    Work Experience:\n",
    "      - Company: Tech Solutions Inc.\n",
    "        Location: San Francisco, USA\n",
    "        Duration: Jan 2015 - Dec 2020\n",
    "        Position: Senior Software Engineer\n",
    "        Projects:\n",
    "          - Name: Inventory Management System\n",
    "            Description: A web-based inventory tracking system.\n",
    "            Technologies: Python, Django, PostgreSQL\n",
    "            Responsibilities: Designed and implemented backend services.\n",
    "    Education:\n",
    "      - University: Stanford University\n",
    "        Year: 2014\n",
    "    Additional Skills: Certified Scrum Master\n",
    "    Additional Information: Received Employee of the Year award (2019).\n",
    "    ```\n",
    "\n",
    "    Expected JSON Output:\n",
    "    ```\n",
    "    dict(\n",
    "      \"name\": \"John Doe\",\n",
    "      \"location\": \"New York, USA\",\n",
    "      \"contact_information\": dict('emai': \"john.doe@example.com, 'phone': 123456789\"),\n",
    "      \"experience\": \"Over 10 years in software development and project management.\",\n",
    "      \"skills\": [\"Python\", \"JavaScript\", \"React\", \"Project Management\", \"Agile Methodologies\"],\n",
    "      \"work_experience\": [\n",
    "        dict(\n",
    "          \"company\": \"Tech Solutions Inc.\",\n",
    "          \"location\": \"San Francisco, USA\",\n",
    "          \"duration\": \"Jan 2015 - Dec 2020\",\n",
    "          \"position\": \"Senior Software Engineer\",\n",
    "          \"projects\": [\n",
    "            dict(\n",
    "              \"name\": \"Inventory Management System\",\n",
    "              \"description\": \"A web-based inventory tracking system.\",\n",
    "              \"technologies\": [\"Python\", \"Django\", \"PostgreSQL\"],\n",
    "              \"responsibilities\": [\"Designed and implemented backend services.\"]\n",
    "            )\n",
    "          ]\n",
    "        )\n",
    "      ],\n",
    "      \"education\": [\n",
    "        dict(\n",
    "          \"university\": \"Stanford University\",\n",
    "          \"year\": \"2014\"\n",
    "        )\n",
    "      ],\n",
    "      \"additional_skills\": [\"Certified Scrum Master\"],\n",
    "      \"additional_information\": [\"Received Employee of the Year award (2019).\"]\n",
    "    )\n",
    "    ```\n",
    "    Now parse the following CV content:\n",
    "    ```\n",
    "    {cv_content}\n",
    "    ```\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = get_gsk_parse_llm(model_name='llama-3.1-70b-versatile')\n",
    "\n",
    "class Project(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    technologies: List[str]\n",
    "    responsibilities: List[str]\n",
    "\n",
    "class WorkExperience(BaseModel):\n",
    "    company: str\n",
    "    location: str\n",
    "    duration: str\n",
    "    position: str\n",
    "    projects: List[Project]\n",
    "\n",
    "class Education(BaseModel):\n",
    "    university: str\n",
    "    year: str\n",
    "\n",
    "class Candidate(BaseModel):\n",
    "    name: str\n",
    "    location: str\n",
    "    contact_information: dict = Field(default_factory=dict)\n",
    "    experience: str\n",
    "    skills: List[str]\n",
    "    work_experience: List[WorkExperience]\n",
    "    education: List[Education]\n",
    "    additional_skills: List[str]\n",
    "    additional_information: List[str]\n",
    "\n",
    "cv_parser = JsonOutputParser(pydantic_object=Candidate)\n",
    "\n",
    "chain = prompt_template | llm | cv_parser\n",
    "\n",
    "info1 = chain.invoke(input={\"cv_content\": CVs_content1})\n",
    "info1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2c4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_instance1 = Candidate(**info1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a9013a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Smith \n",
      "BI / Big Data/ Azure \n",
      "Manchester, UK- Email me on Indeed: indeed.com/r/falicent/140749dace5dc26f \n",
      " \n",
      "10+ years of Experience in Designing, Development, Administration, Analysis, \n",
      "Management inthe Business Intelligence Da ta warehousing, Client Server \n",
      "Technologies, Web-based Applications, cloud solutions and Databases. \n",
      "Data warehouse: Data analysis, star/ snow flake schema data modeling and design \n",
      "specific todata warehousing and business intelligence environment. \n",
      "Database: Experience in database designing, scalability, back -up and recovery, \n",
      "writing andoptimizing SQL code and Stored Procedures, creating functions, views, \n",
      "triggers and indexes.  \n",
      "Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL \n",
      "Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure \n",
      "data lake analytics(U-SQL). \n",
      "Big Data: Worked Azure data lake store/analytics for big data processing and Azure \n",
      "data factoryto schedule U-SQL jobs. Designed and developed end to end big data \n",
      "solution for data insights.  \n",
      " \n",
      "Willing to relocate: Anywhere \n",
      "WORK EXPERIENCESoftware Engineer \n",
      "Microsoft - Manchester, UK. \n",
      "December 2015 to Present \n",
      "1. Microsoft Rewards Live dashboards: \n",
      "Description: - Microsoft rewards is loyalty program that rewards Users for \n",
      "browsing and shopping online. Microsoft Rewards members can earn points when \n",
      "searching with Bing, browsing with Microsoft Edge and making purchases at the \n",
      "Xbox Store, the Windows St ore and the Microsoft Store. Plus, user can pick up \n",
      "bonus points for taking daily quizzes and tours on the Microsoft rewards website. \n",
      "Rewards live dashboards gives a live picture of usage world -wide and by markets \n",
      "like US, Canada, Australia, new user regis tration count, top/bottom performing \n",
      "rewards offers, orders stats and weekly trends of user activities, orders and new \n",
      "user registrations. the PBI tiles gets refreshed in different frequencies starting \n",
      "from 5 seconds to 30 minutes. \n",
      "Technology/Tools used \n",
      "Event hub, stream analytics and Power BI. \n",
      "Responsibilities \n",
      "Created stream analytics jobs to process event hub data \n",
      "Created Power BI live dashboard to show live usage traffic, weekly trends, cards, \n",
      "charts to showtop/bottom 10 offers and usage metrics. \n",
      "2. Microsoft Rewards Data Insights: \n",
      "Description: - Microsoft rewards is loyalty program that rewards Users for \n",
      "browsing and shopping online. Microsoft Rewards members can earn points when \n",
      "searching with Bing, browsing with Microsoft Edge and making purchases at t he \n",
      "Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up \n",
      "bonus points for taking daily quizzes and tours on the Microsoft rewards website. \n",
      "Rewards data insights is data analytics and reporting platform, processes 20 \n",
      "million users daily activities and redemption across different markets like US, \n",
      "Canada, Australia. \n",
      "Technology/Tools used \n",
      "Cosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI. \n",
      "Responsibilities Created big data scripts in cosmos \n",
      "C# data extractors, processors and reducers for data transformation \n",
      "Power BI dashboards \n",
      "3. End to end tracking Tool: \n",
      "Description: - This is real -time Tracking tool to track different business \n",
      "transactions like order, order response, functional acknowledgement, invoice \n",
      "flowing inside ICOE. It gives flexibility to customers to track their transactions \n",
      "and appropriate error information in-case of any failure. Based on resource based \n",
      "access control the tool gives flexibility to end user to perform different actions \n",
      "like view transactions, search based on different filter criteria and view and \n",
      "download actual message payload. End to end tracking tool stitches all the \n",
      "business transaction like order to cash flow and connects different hops inside \n",
      "ICOE like gateway, routing server, Processing server. It also connects different \n",
      "systems like ICOE, partner end point and SAP. \n",
      "Technology/Tools used \n",
      "Azure Document db, Azure web job and Web APP, RBAC, Angular JS. \n",
      "Responsibilities \n",
      "Document dB stored procedures. \n",
      "Web job to process event hub data and populate Document db Web App API. \n",
      "Stream analytics job to transform data \n",
      "Power BI reports \n",
      "4. Biztrack Tracking Tool: \n",
      "Description: - This is real -time Tracking tool to track different business \n",
      "transactions like order, order response, functional acknowledgement, invoice \n",
      "flowing inside ICOE. It gives flexibility to customers to track their transactions \n",
      "and appropriate error information in-case of any failure. Based on resource based \n",
      "access control the tool gives flexibility to end user to perform different actions \n",
      "like view transactions, search based on different filter criteria and view and \n",
      "download actual message payload. \n",
      "Technology/Tools used \n",
      "SQL server 2014, SSIS, .net API, Angular JS. \n",
      "Responsibilities \n",
      "ETL solution to transform business transactions data stored in Biztalk tables. \n",
      "SQL azure tables, stored procedures, User defined functions. \n",
      "Performance tuning. \n",
      "Web API enhancements. \n",
      " \n",
      "EDUCATION \n",
      "The University of Manchester - UK \n",
      "2007 \n",
      " \n",
      "SKILLS \n",
      "problem solving (Less than 1 year), project lifecycle (Less than 1 year), project \n",
      "manager (Less than 1 year), technical assistance. (Less than 1 year) \n",
      "ADDITIONAL INFORMATION \n",
      "Professional Skills \n",
      "Excellent analytical, problem solving, communication, knowledge transfer and \n",
      "interpersonalskills with ability to interact with individuals at all the levels \n",
      "Quick learner and maintains cordial relationship with project manager and team \n",
      "members andgood performer both in team and independent job environments \n",
      "Positive attitude towards superiors &amp; peers Supervised junior developers throughout project lifecycle and provided technical \n",
      "assistance. \n"
     ]
    }
   ],
   "source": [
    "print(CVs_content1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5f0bf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Alice Clark',\n",
       " 'location': 'Delhi, India',\n",
       " 'contact_information': {'email': 'available on Indeed'},\n",
       " 'experience': '20+ years of experience in data handling, design, and development',\n",
       " 'skills': ['Data Warehouse',\n",
       "  'Database',\n",
       "  'Cloud platform',\n",
       "  'Machine Learning',\n",
       "  'Natural Language Processing',\n",
       "  'Big Data Handling'],\n",
       " 'work_experience': [{'company': 'Microsoft',\n",
       "   'location': 'Bangalore, Karnataka',\n",
       "   'duration': 'January 2000 to Present',\n",
       "   'position': 'Software Engineer',\n",
       "   'projects': [{'name': 'Microsoft Rewards Live dashboards',\n",
       "     'description': 'A live picture of usage world-wide and by markets like US, Canada, Australia, new user registration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations.',\n",
       "     'technologies': [],\n",
       "     'responsibilities': []}]}],\n",
       " 'education': [{'university': 'Indian Institute of Technology',\n",
       "   'year': '2001'}],\n",
       " 'additional_skills': [],\n",
       " 'additional_information': ['Excellent analytical, problem solving, communication, knowledge transfer and interpersonal skills with ability to interact with individuals at all the levels',\n",
       "  'Quick learner and maintains cordial relationship with project manager and team members and good performer both in team and independent job environments',\n",
       "  'Positive attitude towards superiors & peers',\n",
       "  'Supervised junior developers throughout project lifecycle and provided technical assistance']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info2 = chain.invoke(input={\"cv_content\": CVs_content2})\n",
    "info2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b37b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_instance2 = Candidate(**info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4fd47fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company='Microsoft' location='Bangalore, Karnataka' duration='January 2000 to Present' position='Software Engineer' projects=[Project(name='Microsoft Rewards Live dashboards', description='A live picture of usage world-wide and by markets like US, Canada, Australia, new user registration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations.', technologies=[], responsibilities=[])]\n"
     ]
    }
   ],
   "source": [
    "print(candidate_instance2.work_experience[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5f51cf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Michael Smith',\n",
       " 'Location': 'Manchester, UK',\n",
       " 'Contact Information': {'Email': 'indeed.com/r/falicent/140749dace5dc26f'},\n",
       " 'Experience': '10+ years',\n",
       " 'Skills': ['BI',\n",
       "  'Big Data',\n",
       "  'Azure',\n",
       "  'Data warehouse',\n",
       "  'Database',\n",
       "  'Cloud platform',\n",
       "  'Problem solving',\n",
       "  'Project lifecycle',\n",
       "  'Project manager',\n",
       "  'Technical assistance'],\n",
       " 'Work Experience': [{'Company': 'Microsoft',\n",
       "   'Location': 'Manchester, UK',\n",
       "   'Duration': 'December 2015 to Present',\n",
       "   'Position': 'Software Engineer',\n",
       "   'Projects': [{'Name': 'Microsoft Rewards Live dashboards',\n",
       "     'Description': 'A live picture of usage worldwide and by markets like US, Canada, Australia, new user registration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations.',\n",
       "     'Technologies': ['Event hub', 'Stream analytics', 'Power BI'],\n",
       "     'Responsibilities': ['Created stream analytics jobs to process event hub data',\n",
       "      'Created Power BI live dashboard to show live usage traffic, weekly trends, cards, charts to show top/bottom 10 offers and usage metrics']},\n",
       "    {'Name': 'Microsoft Rewards Data Insights',\n",
       "     'Description': 'A data analytics and reporting platform, processes 20 million users daily activities and redemption across different markets like US, Canada, Australia.',\n",
       "     'Technologies': ['Cosmos (Microsoft big-data platform)',\n",
       "      'C#',\n",
       "      'X-flow job monitoring',\n",
       "      'Power BI'],\n",
       "     'Responsibilities': ['Created big data scripts in cosmos',\n",
       "      'C# data extractors, processors and reducers for data transformation',\n",
       "      'Power BI dashboards']},\n",
       "    {'Name': 'End to end tracking Tool',\n",
       "     'Description': 'A real-time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing inside ICOE.',\n",
       "     'Technologies': ['Azure Document db',\n",
       "      'Azure web job and Web APP',\n",
       "      'RBAC',\n",
       "      'Angular JS'],\n",
       "     'Responsibilities': ['Document dB stored procedures',\n",
       "      'Web job to process event hub data and populate Document db Web App API',\n",
       "      'Stream analytics job to transform data',\n",
       "      'Power BI reports']},\n",
       "    {'Name': 'Biztrack Tracking Tool',\n",
       "     'Description': 'A real-time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing inside ICOE.',\n",
       "     'Technologies': ['SQL server 2014', 'SSIS', '.net API', 'Angular JS'],\n",
       "     'Responsibilities': ['ETL solution to transform business transactions data stored in Biztalk tables',\n",
       "      'SQL azure tables, stored procedures, User defined functions',\n",
       "      'Performance tuning',\n",
       "      'Web API enhancements']}]}],\n",
       " 'Education': [{'University': 'The University of Manchester', 'Year': '2007'}],\n",
       " 'Additional Skills': ['Excellent analytical, problem solving, communication, knowledge transfer and interpersonal skills',\n",
       "  'Quick learner and maintains cordial relationship with project manager and team members',\n",
       "  'Good performer both in team and independent job environments',\n",
       "  'Positive attitude towards superiors & peers',\n",
       "  'Supervised junior developers throughout project lifecycle and provided technical assistance'],\n",
       " 'Additional Information': ['Excellent analytical, problem solving, communication, knowledge transfer and interpersonal skills',\n",
       "  'Quick learner and maintains cordial relationship with project manager and team members',\n",
       "  'Good performer both in team and independent job environments',\n",
       "  'Positive attitude towards superiors & peers',\n",
       "  'Supervised junior developers throughout project lifecycle and provided technical assistance']}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate1.work_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0800a385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate1 = map_dict_to_candidate(info1)\n",
    "\n",
    "candidate1.work_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "113a447c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Candidate at 0x213c1a476d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate2 = map_dict_to_candidate(info1)\n",
    "\n",
    "candidate1.work_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48ec4746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Microsoft Rewards Live Dashboards',\n",
       "  'description': 'Real-time dashboards for Microsoft Rewards program',\n",
       "  'technologies': ['Event Hub', 'Stream Analytics', 'Power BI'],\n",
       "  'responsibilities': ['Created stream analytics jobs to process event hub data',\n",
       "   'Created Power BI live dashboard to show live usage traffic, weekly trends, cards, charts to show top/bottom 10 offers and usage metrics']},\n",
       " {'name': 'Microsoft Rewards Data Insights',\n",
       "  'description': 'Data analytics and reporting platform for Microsoft Rewards program',\n",
       "  'technologies': ['Cosmos (Microsoft big-data platform)',\n",
       "   'C#',\n",
       "   'X-flow job monitoring',\n",
       "   'Power BI'],\n",
       "  'responsibilities': ['Created big data scripts in cosmos',\n",
       "   'C# data extractors, processors and reducers for data transformation',\n",
       "   'Power BI dashboards']},\n",
       " {'name': 'End to End Tracking Tool',\n",
       "  'description': 'Real-time tracking tool for business transactions',\n",
       "  'technologies': ['Azure Document DB',\n",
       "   'Azure Web Job',\n",
       "   'Web App',\n",
       "   'RBAC',\n",
       "   'Angular JS'],\n",
       "  'responsibilities': ['Document DB stored procedures',\n",
       "   'Web job to process event hub data and populate Document DB Web App API',\n",
       "   'Stream analytics job to transform data',\n",
       "   'Power BI reports']},\n",
       " {'name': 'Biztrack Tracking Tool',\n",
       "  'description': 'Real-time tracking tool for business transactions',\n",
       "  'technologies': ['SQL Server 2014', 'SSIS', '.NET API', 'Angular JS'],\n",
       "  'responsibilities': ['ETL solution to transform business transactions data stored in Biztalk tables',\n",
       "   'SQL Azure tables, stored procedures, User defined functions',\n",
       "   'Performance tuning',\n",
       "   'Web API enhancements']}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['workExperience'][0]['roles'][0]['projects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0925eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c935326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\basellmchatbot\\lib\\site-packages\\langchain_groq\\chat_models.py:362: UserWarning: WARNING! gsk_token is not default parameter.\n",
      "                    gsk_token was transferred to model_kwargs.\n",
      "                    Please confirm that gsk_token is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "temp = ChatGroq(\n",
    "    temperature=0.6,\n",
    "    model_name = \"llama-3.1-70b-versatile\",\n",
    "    gsk_token = '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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c29bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gsk_parse_llm(model_name: str = \"llama-3.1-70b-versatile\", **kwargs):\n",
    "    \"\"\"\n",
    "    Initializes a ChatGroq language model with specified parameters.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model to initialize.\n",
    "        **kwargs: Additional parameters to customize the ChatGroq instance.\n",
    "\n",
    "    Returns:\n",
    "        ChatGroq: The initialized language model.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the GROQ_API_KEY is not set in the environment.\n",
    "    \"\"\"\n",
    "    llm = ChatGroq(\n",
    "        model_name = model_name,\n",
    "        model_kwargs = kwargs\n",
    "    )\n",
    "    return llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c8ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7600ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basellmchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
